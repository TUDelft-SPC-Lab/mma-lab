{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Introduction to OpenCV and\n",
    "Reciprocal Recommendation\n",
    " </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{CSE2230 Multimedia Analysis}\\\\\n",
    "\\text{2021-2022 Q3 Week 1}\\\\\n",
    "\\textbf{Deadline:}\\text{ 15 Feburary 2022}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collection\n",
    "Before you start, please fill in your ice cream consumption counts in the form:\n",
    "\n",
    "TODO\n",
    "\n",
    "Remember to keep your counts secret. Don’t let your neighbors know how you filled in the survey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to submit your work:\n",
    "After making this jupiter notebook, in brightspace you can find under Lab -> Lab 1 -> YOURNAME_LAB1.docx. Fill in this document and convert it to a PDF or Docx file. In brightspace under assigments there will be a assigment called **\"Lab 1\"**. Here you can hand in the PDF or Docx you just created with your answers and prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our goals today:\n",
    "\n",
    "### Part 1: OpenCV\n",
    "Your overall mission for Part 1 today is to become familiar with OpenCV, a computer vision library that we will use in this course for image processing and video processing. You will revisit familiar territory: image convolution and the Sobel filter.\n",
    "\n",
    "In this course, we treat topics from two perspectives: algorithm perspective and user perspective. Here is how you learn from both these perspectives in Part 1: \n",
    "\n",
    "In this course, we learn about image and video processing in two ways:\n",
    "1. **Algorithm perspective:** Here, you learn by implementation. You look at code and you implement extractors for features or generators for descriptors, in part or in full. \n",
    "2. **User perspective:** Here, you learn by observation and experimentation. You look at images, and think about what you “see”, not as a computer scientist, but as a user of a multimedia system. Different features are able to capture different aspects of what people see when they look at and compare images. \n",
    "\n",
    "These two perspectives will become clearer next week, as we look at image retrieval systems.\n",
    "\n",
    "### Part 2: Reciprocal Recommendation\n",
    "Your overall mission for Part 2 is to build a simple recommender system. The recommender system is a “pairing algorithm”, which will pair people in the course based on their self-reported ice cream eating behavior. For this task, we will use an Ice Cream Consumption data set that we create ourselves. \n",
    "\n",
    "Here in Part 2, we also have learn two perspectives:\n",
    "1. **Algorithm perspective:** Here, you learn by implementation. You become familiar with the distance measures and metrics that we learned about in class, and you also have a chance to experiment with normalization.\n",
    "2. **User perspective:** Here, you learn by exercising your creativity. First, think about what the consumption counts in the Ice Cream Consumption data set might actually reflect about the individual users. Then, think about how to make a connection between two users based on what you assume/believe that the counts reflect. The connection that you make should be intended to lead to a happy collaborative relationship between the two people. \n",
    "\n",
    "We will use the “pairing algorithms” that you create in order to assign lab partners in the labs starting next week. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Introduction to Open CV\n",
    "\n",
    "### 1.1 Loading and showing an Image using OpenCV\n",
    "Create a function that loads in the `bookshelf.jpg` image by using:\n",
    "\n",
    "    import cv2 # this imports the OpenCV functions \n",
    "    im = cv2.imread(’Images/bookshelf.jpg’) \n",
    "    cv2.imshow(’Books image’, im) \n",
    "    cv2.waitKey()\n",
    "\n",
    "We can convert it to grayscale by using:\n",
    "\n",
    "    gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY) \n",
    "    cv2.imshow(’Grayscale’, gray) \n",
    "    cv2.waitKey()\n",
    "\n",
    "Firstly, you should see an BGR version of the image show. After closing the window the next one will automaticcaly open with the grayscale image.\n",
    "\n",
    "If `cv2.imshow()` gives a weird screen you can use matplotlib to show images like this:\n",
    "\n",
    "    import matplotlib.pyplot as plt \n",
    "    plt.imshow(im) \n",
    "    plt.show()\n",
    "\n",
    "Note that matplotlib uses RGB images instead of OpenCV's BGR color format.\n",
    "The `waitKey()` call species that the window should stay open until the cross is pressed. Otherwise it will close immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# Start answer here\n",
    "\n",
    "# End answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Creating images with Numpy\n",
    "Besides loading images, we can also create images using numpy. For example, we can create a matrix of random data and show it as an image.\n",
    "\n",
    "    import numpy as np\n",
    "    m_grey = np.random.rand(200,200)\n",
    "    im_bgr = np.random.rand(200,200,3)\n",
    "\n",
    "Show these images using the code introduced above.\n",
    "Create an image which is all black or an image which only has white pixels\n",
    "(choose one or the other). Hint: If you know what values are needed for these\n",
    "images, numpy has nice functions to obtain them.\n",
    "\n",
    "Implement a function that convolves a grayscale image (you can use `bookshelf.jpg`) with the $3x3$ matrices (kernels $G_x$, $G_y$) shown below.\n",
    "\n",
    "![Kernel](Images/Kernel.PNG)\n",
    "\n",
    "Remember the operator * means convolution:\n",
    "$$\n",
    "f*g[n]=\\sum f[m]g[n-m]\n",
    "$$\n",
    "Return as a result the square root of the sum of squares of Gx and Gy and show the image. \n",
    "\n",
    "Note that above: $I$ is the image and $G_x$ and $G_y$ represent the filtered image in the $x$ and $y$ direction respectively. Start with the second row and the second column and go to the penultimate row and penultimate column. In this way, you will avoid issues with the image boundaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Answer the following question:***\n",
    "\n",
    "What is the expected result and why do you think that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write your answer here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "    ANSWER\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code should consist of the following parts:\n",
    "1. Load the image \n",
    "2. Create Gx and Gy as empty Numpy arrays\n",
    "3. Create a function that performs a convolution. hint: nested for loops for x and y coordinates\n",
    "4. Do the convolution of the image with filters Gx and Gy (Do not forget the flipping of the kernels with convolution operations) and store the results in Gx and Gy.\n",
    "5. Combine the results using Pythagoras' Theorem (Euclidean distance) (there\n",
    "is a OpenCV method for this) (be careful for overflowing values)\n",
    "6. Show the output image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def convolution(gray_img, kernel):\n",
    "    # Start answer here\n",
    "    \n",
    "    # End snswer here\n",
    "\n",
    "Gx = None\n",
    "Gy = None\n",
    "# Start answer here\n",
    "\n",
    "# End answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Answer the following question:***\n",
    "\n",
    "State whether the result upheld your expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "ANSWER\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Use a filter from OpenCV\n",
    "Instead of implementing our own Sobel filter, we will\n",
    "use the one provided by OpenCV. Load the grayscale image again, and take the\n",
    "derivative by using:\n",
    "\n",
    "`Gx = cv2.Sobel(gray, -1, 1, 0, 3)`\n",
    "\n",
    "Read up on what each parameter means in the OpenCV documentation. Obtain\n",
    "the derivative in the y-direction as well, and combine the two into an image gradient\n",
    "using either the Euclidean distance or the sum of the absolute values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start answer here\n",
    "\n",
    "# End Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Answer the following question:***\n",
    "\n",
    "Describe whether the result of the OpenCV based filter looks like the result you obtained earlier. If not, can you think of a reason why? (there may be some hints in the documentation above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write your answer here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "    ANSWER\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Other OpenCV functions\n",
    "1. Displaying an image where all the colors are fully saturated, by using OpenCV's `cvtColor` function.\n",
    "2. Search for the `dilate` function in OpenCV and apply it to your image. Use a 5x5 kernel.\n",
    "\n",
    "Besides `dilate` OpenCV also provides functions to filter images such as `blur`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Color Histogram\n",
    "Next, we will explore the color histogram with `theDress.jpeg` which is included in\n",
    "the image folder on the VM. The color histogram is an example of a “global feature”, which means that each component of the vector represents the whole image (as opposed to representing a small region). In a color histogram, we simply count how many times each value of a color is present in a picture. A color histogram expresses the color information as three separate histograms.\n",
    "\n",
    "Implement your own color histogram algorithm using the following function body. Add your code to your google docs report. For our case, use num bins = `256` and\n",
    "num channels = `3`.\n",
    "\n",
    "```\n",
    "def my_colorHist(im, num_bins):\n",
    "    #Your code goes here\n",
    "    return histogram\n",
    "``` \n",
    "\n",
    "The function accepts an image, the number of histogram bins. It should return a\n",
    "histogram (Numpy array) for all color channels in the image, of size num bins x\n",
    "num channels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Answer the following question:***\n",
    "\n",
    "What do you expect that the histogram will look like. Relate your answer to the colors that you perceive the dress to be.\n",
    "\n",
    "#### Write your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "ANSWER\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_colorHist(im, num_bins):\n",
    "    histogram = None\n",
    "    # Start answer here\n",
    "    \n",
    "    # End answer here\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have experience with Matplotlib, there are excellent quick tutorials online to familiarize yourself with the basics\n",
    "\n",
    "(https://matplotlib.org/tutorials/introductory/pyplot.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Testing your algorithm\n",
    "An easy way to validate your algorithm is by comparing it to other implementations\n",
    "of a color histogram algorithm. Numpy, OpenCV and Matplotlib all have similar functions.\n",
    "\n",
    "#### ***Answer the following question:***\n",
    "Compare the results by creating a nice plot of both your result of my_colorHist() and one of the library color histogram functions. Is there a difference between the two plots? If so, why? Is this what you were expecting? Why or why not?\n",
    "\n",
    "#### Write your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "ANSWER\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Recommender Systems\n",
    "For this part, you will need the Ice Cream Consumption Data Set:\n",
    "\n",
    "TODO\n",
    "\n",
    "Ask one of the TAs if you get this far, and a link to the file has not yet been provided. Each line of the file represents one student, and the line format is:\n",
    "\n",
    "`id,flav1count,flav2count,...,flavNcount`\n",
    "whereby `flavxcount = {1|2|3|4|5|6|7|8|9}` or is empty.\n",
    "\n",
    "If you're not already familiar with Python, make the `intro1-python.ipynb` and `intro2-numpy.ipynb`. This will provide some extra knowledge about Python 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Reading the file\n",
    "In this assigment we are going to read in the data. Read in the data and print it in the following way:\n",
    "\n",
    "```\n",
    "ID Flav1Count Flav2Count ... FlavNCount\n",
    "name1 3 <empty> ... 2\n",
    "name2 <empty> 7 ... 1\n",
    "name3 3 6 ... 2\n",
    "name4 5 1 ... <empty>\n",
    "name5 <empty> <empty> ... <empty>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start answer here\n",
    "\n",
    "# End Answer here\n",
    "\n",
    "pratice_data = [[10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0],\n",
    "[9.0, 8.0, 9.0, 8.0, 9.0, 7.0, 4.0, 2.0, 9.0, 5.0],\n",
    "[9.0, 7.0, 6.0, 7.0, 4.0, 4.0, 7.0, 1.0, 7.0, 4.0],\n",
    "[3.0, 6.0, 5.0, 3.0, 4.0, 3.0, 5.0, 7.0, 8.0, 8.0],\n",
    "[4.0, 5.0, 4.0, 2.0, 5.0, 6.0, 4.0, 6.0, 7.0, 8.0],\n",
    "[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Making a distance function (i.e., a type of similarity measure)\n",
    "Our purpose here is to get an understanding of recommender systems. A recommender system is a system that automatically predicts user preferences, usually in the form of items that a user might like or be interested in. \n",
    "\n",
    "First, we implement a very simple way of calculating pairwise similarity between users, where a user’s preferences are represented as a vector. We then make the assumption that consumption counts reflect characteristics of people that are related to their potential compatibility as lab partners. On the basis of this assumption we divide our set of users into pairs. \n",
    "\n",
    "From the previous exercises, remove all of the code except the line that prints the exercise title. Next define a Euclidean distance function as follows:\n",
    "\n",
    "    def euclidean_distance(p,q):\n",
    "        # your code goes here\n",
    "    \n",
    "Like with the loops, the indentation again specifies the scope of the function. You don't need to specify the return type or parameter types of the function like you would in Java. Note that the same worked for the apps variable earlier. For this distance function, we're going to assume a few things. Both parameters p and q are n dimensional vectors, of the same dimension which is greater than 0. The equation for Euclidean distance in n dimensions is:\n",
    "$$\n",
    "    d(p,q)=\\sqrt{(p_1-q_1)^2+(p_2-q_2)^2+...(p_n-q_n)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def euclidean_distance(p,q):\n",
    "    result = None\n",
    "    # Start answer here\n",
    "\n",
    "    # End Answer here\n",
    "    return result\n",
    "\n",
    "test_p = [4,8,1,5,1,6,2,3,4,2]\n",
    "test_q = [3,2,2,3,9,4,0,4,2,6]\n",
    "assert(math.isclose(11.61895003862225, euclidean_distance(test_p, test_q), rel_tol=1e-5))\n",
    "assert(math.isclose(0.0, euclidean_distance(test_p, test_p), rel_tol=1e-5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Making a normalization function\n",
    "We want to control the effects of the relative vector magnitudes on their distance, therefore we introduce a normalization step.\n",
    "\n",
    "Assume for now that all values in the vectors range from 0 to 9. In that case, we only have to divide each entry by that maximum. Note that there are many ways to normalize values, the ‘correct’ way depends on the application. In lecture, for example, we discussed normalizing vectors with their lengths to obtain unit vectors. Here, we normalize with the value of the maximum component. This is also a possible choice for normalization, that can be useful in practice.\n",
    "\n",
    "    def normalize_vector(p, maximum):\n",
    "        # your code goes here\n",
    "\n",
    "Create the `normalize_vector`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vector(p, maximum):\n",
    "    result = None\n",
    "    # Start answer here\n",
    "    \n",
    "    # End Answer here\n",
    "    return result\n",
    "\n",
    "test_answer_p = [0.4444444444444444, 0.8888888888888888, 0.1111111111111111, 0.5555555555555556, 0.1111111111111111, 0.6666666666666666, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.2222222222222222]\n",
    "test_answer_q = [0.3333333333333333, 0.2222222222222222, 0.2222222222222222, 0.3333333333333333, 1.0, 0.4444444444444444, 0.0, 0.4444444444444444, 0.2222222222222222, 0.6666666666666666]\n",
    "test_result_p = normalize_vector(test_p, 9)\n",
    "test_result_q = normalize_vector(test_q, 9)\n",
    "\n",
    "for i in range(len(test_answer_p)):\n",
    "    assert(math.isclose(test_answer_p[i], test_result_p[i], rel_tol=1e-5))\n",
    "    assert(math.isclose(test_answer_q[i], test_result_q[i], rel_tol=1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Calculating the distance matrix\n",
    "If there are $n$ vectors, a not so smart solution would be building a $n$ by $n$ distance matrix ending up with $n^2$ entries. However, since Euclidean distance is symmetric and we don't care about a vector's distance to itself, we actually only need to fill in only a part of the distance matrix.\n",
    "\n",
    "A handy function for this is the `range()` function. Which is a build in function in Python.\n",
    "\n",
    "A few things are useful to remember here. The use of tuples, because it is faster and safer (as they are immutable). The range function can run from a lower bound to the non-inclusive upper bound. Python control flow functionality can be seen here. Note that control flow statements end with a colon “:” and indentation is used to demarcate their scope.\n",
    "\n",
    "Finish the `distance_matrix(vectors)` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix(vectors):\n",
    "    result = []\n",
    "    N = None\n",
    "    # Start answer here\n",
    "    \n",
    "    # End Answer here\n",
    "    for i in range(N):\n",
    "        for j in range(i+1,N):\n",
    "            ind = None\n",
    "            dis = None\n",
    "            # Start answer here\n",
    "            \n",
    "            # End Answer here\n",
    "            result.append( (ind, dis) )\n",
    "            \n",
    "    return result\n",
    "\n",
    "D = distance_matrix([test_p, test_q, test_p])\n",
    "D_answer = [[(0, 1), 11.61895003862225], [(0, 2), 0.0], [(1, 2), 11.61895003862225]]\n",
    "for i in range(len(D)):\n",
    "    assert(D[i][0][0] == D_answer[i][0][0])\n",
    "    assert(D[i][0][1] == D_answer[i][0][1])\n",
    "    assert(math.isclose(D[i][1], D_answer[i][1], rel_tol=1e-5))\n",
    "    \n",
    "pratice_data_distances = distance_matrix(pratice_data)\n",
    "pratice_data_distances = sorted(pratice_data_distances, key=lambda pratice_data_distances: pratice_data_distances[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Use the functions\n",
    "Now we have made different functions we can use our data to calculate a score for every pair. Use the data you read in in 2.1 to make the distance matrix. Your result should look a bit like the following if sorted:\n",
    "\n",
    "    Pairers\n",
    "    (3, 4), 4.123105625617661\n",
    "    (4, 5), 6.6332495807108\n",
    "    (3, 5), 6.708203932499369\n",
    "    (1, 2), 7.745966692414834\n",
    "    (0, 2), 7.810249675906654\n",
    "    (0, 1), 9.1104335791443\n",
    "    (2, 3), 10.583005244258363\n",
    "    (2, 4), 10.63014581273465\n",
    "    (1, 4), 11.874342087037917\n",
    "    (1, 3), 12.569805089976535\n",
    "    (0, 4), 13.341664064126334\n",
    "    (0, 3), 13.892443989449804\n",
    "    (2, 5), 14.177446878757825\n",
    "    (1, 5), 15.459624833740307\n",
    "    (0, 5), 18.16590212458495\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start answer here\n",
    "\n",
    "# End Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Matching Pairs\n",
    "Looking ahead to what is to come: When you make an actual matching algorithm, you might want to consider what measure you want to optimize. For example, do you want to make it so that there is no pairing for which every participant is equally satisfied or better off (Pareto optimal), or do you want to optimize such that the worst pairing is still as good as possible (Egalitarian). Maybe you want neither of those but include some other neat feature?\n",
    "\n",
    "Now back to where we are now: Right now, we are going for a greedy approach. \n",
    "\n",
    "Moving on: We allocate a pair from our sorted list based on closeness. The participants from that pairing are then no longer eligible to be paired with another participant. We need to do a bit of bookkeeping, so we don't match a participant that is already in a pair:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pairs(data):\n",
    "    paired = []\n",
    "    pairs = []\n",
    "    \n",
    "    for d in data:\n",
    "        # add next closest pair\n",
    "        closest_pair = d[0]\n",
    "    \n",
    "        # indicate participants are now paired\n",
    "        p = closest_pair[0]\n",
    "        q = closest_pair[1]\n",
    "        \n",
    "        # check if pairs are in paired if not add this pair to pairs\n",
    "        if p not in paired and q not in paired:\n",
    "            paired.append(p)\n",
    "            paired.append(q)\n",
    "            pairs.append(closest_pair)\n",
    "    return pairs\n",
    "\n",
    "returned_pairs = find_pairs(pratice_data_distances)\n",
    "\n",
    "for p in returned_pairs:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things happen here. The function `find_pairs` assumes that the input data is sorted. From this assumption we loop over the array from the smallest distance to the biggest distance of 2 pairs. For the pairings, we only want the pair tuple, not the distance (though there would be nothing wrong with including that). We can simply put a [0] behind the the variable `d` and Python will understand that we mean the first entry of the tuple. From this we will get another tuple with two participants `p` and `q`. Now we simply have to check if one of them is already paired or not. If so we skip this one. If both are not paired yet, we add them to our pairs together.\n",
    "\n",
    "At this point we have a very basic pairer based on an arbitrary toy example. Clearly coding like this normally is a bad idea. Next up, we'll be extending it to look more like a proper program, which can use participant IDs, does some exception handling, can load the participants from a file, and that uses modules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Cosine Similarity\n",
    "Consider the formula for cosine similarity between two vectors. n is the number of components in the vectors, which must be the same:\n",
    "![Cosine Similarity](Images/Cosine_Sim.PNG)\n",
    "\n",
    "We see that the numerator is the dot product, i.e.,  a sum over the element-wise multiplication between two vectors. Trivially, we could implement this using a for loop, such as:\n",
    "\n",
    "    def cosine_similarity(p, q):\n",
    "        denominator = 0\n",
    "        for i in range(len(p)):\n",
    "            denominator += p[i] * q[i]\n",
    "        # The rest of the code\n",
    "\n",
    "However, we already dealt with loops so now let’s use NumPy, a Python math library that is written in C for speed, is very suited for this kind of mathematical code. (From wiki:) NumPy is an extension to the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. \n",
    "\n",
    "Below import csv add import numpy. If you are not already, you will soon be convinced that NumPy is well suited for vectorized mathematical computations.\n",
    "\n",
    "Using numpy, we can implement cosine similarity as follows:\n",
    "\n",
    "    import numpy as np\n",
    "    def cosine_similarity(p, q):\n",
    "        numer = np.sum(np.multiply(p,q))\n",
    "        denom = np.sqrt(np.sum(np.square(p)))*np.sqrt(np.sum(np.square(q)))\n",
    "    \n",
    "        if denom is not 0:\n",
    "            return float(numer) / denom\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "Note that we use the convention where numpy is called as np to save some space on the line. \n",
    "\n",
    "Foreshadowing topics to come, we provide the following example: using a numpy array we can work on array elements in the same way as we might in Matlab. Suppose we have an image in RGB format, that has the dimensions N by M by 3, and we want to zero the R channel.\n",
    "\n",
    "    # im contains the NxMx3 matrix\n",
    "    im_numpy = np.array(im)\n",
    "    im[:,:,0] = 0\n",
    "\n",
    "Back to the problem at hand: since the cosine distance is common distance measure, we could have also simply used:\n",
    "\n",
    "    from scipy.spatial.distance import cosine\n",
    "\n",
    "to compute the cosine similarity. scipy is a module which is commonly used in scientific computations. We can now use this to check the correctness of our implementation:\n",
    "\n",
    "    A = scores['oon']\n",
    "    B = scores['ger']\n",
    "    print \"own: \\t\", cosine_similarity(A, B)\n",
    "    print \"check: \\t\", 1 - cosine(A, B)\n",
    "\n",
    "We use the 1  - cosine(A,B) since we would like a similarity, and the scipy implementation expresses distance, cf. http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.distance.cosine.html#scipy.spatial.distance.cosine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Create a pairing algorithm \n",
    "Collaborative Filtering (CF) is a class of methods that recommend items to users based on the preferences other users have expressed for those items. In other words, a CF recommender system exploits past behavior of the user. For example, bol.com will recommend books to you based on which books you have purchased in the past. In this lab “past behavior” is taken to be the consumption counts that we collected. We assume that people’s past ice cream reflects something about them that reflects their compatibility in a collaborative relationship.\n",
    "\n",
    "Create a pairing algorithm using Python. It should operate on a csv file of the same format as the Ice Cream Consumption Data Set file that we have been working at. \n",
    "\n",
    "The pairing algorithm should put all students in the files into pairs, and rank the pairs in order of the goodness of the match. \n",
    "\n",
    "Your pairing algorithm should be able to elegantly handle an odd number of students by creating one group of three.\n",
    "\n",
    "Its output should be a plain text file with human readable pairings. Scores do not have to be normalized, but if you would like to normalize them, that’s fine. The best match should be on top, the worst at the bottom. Example:\n",
    "\n",
    "    1. oonger 1.00 (Boon, Jager)\n",
    "    2. sonung 0.91 (Larson, Hung)\n",
    "    3. eraiou 0.91 (Cabrera,Demetriou)\n",
    "    4. linese 0.40  (Palin, Cleese)\n",
    "    5. mandle -0.45 (Chapman, Idle)\n",
    "\n",
    "Give a bit of thought as to what the consumption counts in the Ice Cream Consumption Data Set file reflect about the people who generated them. Think about how whatever the counts reflect could be used as a basis for connecting people. The people should be connected in such a way that they work well together in a collaborative partnership.\n",
    "\n",
    "Remember that your algorithm should address one or more of the challenges of recommender systems that were introduced in the first lecture this week:\n",
    "\n",
    "- Sparsity,\n",
    "- Cold start,\n",
    "- Little overlap,\n",
    "- Noise,\n",
    "- How to interpret ratings or interactions?\n",
    "- How to interpret lack of ratings or interactions?\n",
    "\n",
    "Think broadly: you could create a new normalization, a new adjustment, a new representation (transform this vector in another vector), a new vector similarity, a new algorithm. Go beyond the greedy assignment used above if you can.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create here your pairing algorithm, this \n",
    "# should be a standalone cell. Therefor \n",
    "# start with all imports you use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Answer the following question:***\n",
    "Create a pitch for your algorithm of 100 words. This pitch should explain your algorithm briefly and clearly, and also “sell” the best features of your algorithm to your fellow students. Remember to mention in your description the way in which your pairing algorithm seeks to deliver the best possible pairings for the users of the pairing recommender system. In other words, why should the users be particularly happy with these pairs?\n",
    "\n",
    "#### Write your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "ANSWER\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
