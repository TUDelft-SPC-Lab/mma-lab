{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Introduction to OpenCV and\n",
    "Reciprocal Recommendation\n",
    " </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{CSE2230 Multimedia Analysis}\\\\\n",
    "\\text{2021-2022 Q3 Week 1}\\\\\n",
    "\\textbf{Deadline:}\\text{ 15 Feburary 2022}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collection\n",
    "Before you start, please fill in your ice cream consumption counts in the form:\n",
    "\n",
    "Remember to keep your counts secret. Don’t let your neighbors know how you filled in the survey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to submit your work:\n",
    "After making this jupiter notebook, in brightspace you can find under Lab -> Lab 1 -> YOURNAME_LAB1.docx. Fill in this document and convert it to a PDF or Docx file. In brightspace under assigments there will be a assigment called **\"Lab 1\"**. Here you can hand in the PDF or Docx you just created with your answers and prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our goals today:\n",
    "\n",
    "### Part 1: OpenCV\n",
    "Your overall mission for Part 1 today is to become familiar with OpenCV, a computer vision library that we will use in this course for image processing and video processing. You will revisit familiar territory: image convolution and the Sobel filter.\n",
    "\n",
    "In this course, we treat topics from two perspectives: algorithm perspective and user perspective. Here is how you learn from both these perspectives in Part 1: \n",
    "\n",
    "In this course, we learn about image and video processing in two ways:\n",
    "1. **Algorithm perspective:** Here, you learn by implementation. You look at code and you implement extractors for features or generators for descriptors, in part or in full. \n",
    "2. **User perspective:** Here, you learn by observation and experimentation. You look at images, and think about what you “see”, not as a computer scientist, but as a user of a multimedia system. Different features are able to capture different aspects of what people see when they look at and compare images. \n",
    "\n",
    "These two perspectives will become clearer next week, as we look at image retrieval systems.\n",
    "\n",
    "### Part 2: Reciprocal Recommendation\n",
    "Your overall mission for Part 2 is to build a simple recommender system. The recommender system is a “pairing algorithm”, which will pair people in the course based on their self-reported ice cream eating behavior. For this task, we will use an Ice Cream Consumption data set that we create ourselves. \n",
    "\n",
    "Here in Part 2, we also have learn two perspectives:\n",
    "1. **Algorithm perspective:** Here, you learn by implementation. You become familiar with the distance measures and metrics that we learned about in class, and you also have a chance to experiment with normalization.\n",
    "2. **User perspective:** Here, you learn by exercising your creativity. First, think about what the consumption counts in the Ice Cream Consumption data set might actually reflect about the individual users. Then, think about how to make a connection between two users based on what you assume/believe that the counts reflect. The connection that you make should be intended to lead to a happy collaborative relationship between the two people. \n",
    "\n",
    "We will use the “pairing algorithms” that you create in order to assign lab partners in the labs starting next week. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Introduction to Open CV\n",
    "\n",
    "### 1.1 Loading and showing an Image using OpenCV\n",
    "Create a function that loads in the `bookshelf.jpg` image by using:\n",
    "\n",
    "`import cv2 # this imports the OpenCV functions \n",
    "im = cv2.imread(’../Images/bookshelf.jpg’) \n",
    "cv2.imshow(’Books image’, im) \n",
    "cv2.waitKey()`\n",
    "\n",
    "We can convert it to grayscale by using:\n",
    "\n",
    "`gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY) \n",
    "cv2.imshow(’Grayscale’, gray) \n",
    "cv2.waitKey()`\n",
    "\n",
    "Firstly, you should see an BGR version of the image show. After having pressed any key in the pop up window you will see a Gray scale version show. Pressing any key in the window a third time will close the script.\n",
    "\n",
    "If `cv2.imshow()` gives a weird screen you can use matplotlib to show images like this:\n",
    "\n",
    "`import matplotlib.pyplot as plt \n",
    "plt.imshow(im) \n",
    "plt.show()`\n",
    "\n",
    "Note that matplotlib uses RGB images instead of OpenCV's BGR color format.\n",
    "The `waitKey()` call species that the window should stay open until the cross is pressed. Otherwise it will close immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Creating images with Numpy\n",
    "Besides loading images, we can also create images using numpy. For example, we can create a matrix of random data and show it as an image.\n",
    "\n",
    "` import numpy as np\n",
    "m_grey = np.random.rand(200,200)\n",
    "im_bgr = np.random.rand(200,200,3)`\n",
    "\n",
    "Show these images using the code introduced above.\n",
    "Create an image which is all black or an image which only has white pixels\n",
    "(choose one or the other). Hint: If you know what values are needed for these\n",
    "images, numpy has nice functions to obtain them.\n",
    "\n",
    "Implement a function that convolves a grayscale image (you can use `bookshelf.jpg`) with the $3x3$ matrices (kernels $G_x$, $G_y$) shown below.\n",
    "\n",
    "![Kernel](Images/Kernel.PNG)\n",
    "\n",
    "Remember the operator * means convolution:\n",
    "$$\n",
    "f*g[n]=\\sum f[m]g[n-m]\n",
    "$$\n",
    "Return as a result the square root of the sum of squares of Gx and Gy and show the image. \n",
    "\n",
    "Note that above: $I$ is the image and $G_x$ and $G_y$ represent the filtered image in the $x$ and $y$ direction respectively. Start with the second row and the second column and go to the penultimate row and penultimate column. In this way, you will avoid issues with the image boundaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Answer the following question:***\n",
    "\n",
    "What is the expected result and why do you think that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write your answer here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code should consist of the following parts:\n",
    "1. Load the image \n",
    "2. Create Gx and Gy as empty Numpy arrays\n",
    "3. Create a function that performs a convolution. hint: nested for loops for x and y coordinates\n",
    "4. Do the convolution of the image with filters Gx and Gy (Do not forget the flipping of the kernels with convolution operations) and store the results in Gx and Gy.\n",
    "5. Combine the results using Pythagoras' Theorem (Euclidean distance) (there\n",
    "is a OpenCV method for this) (be careful for overflowing values)\n",
    "6. Show the output image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(image, kernel):\n",
    "    # Start answer here\n",
    "    \n",
    "    # End snswer here\n",
    "    \n",
    "# Start answer here\n",
    "\n",
    "# End answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Answer the following question:***\n",
    "\n",
    "State whether the result upheld your expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Use a filter from OpenCV\n",
    "Instead of implementing our own Sobel filter, we will\n",
    "use the one provided by OpenCV. Load the grayscale image again, and take the\n",
    "derivative by using:\n",
    "\n",
    "`Gx = cv2.Sobel(gray, -1, 1, 0, 3)`\n",
    "\n",
    "Read up on what each parameter means in the OpenCV documentation. Obtain\n",
    "the derivative in the y-direction as well, and combine the two into an image gradient\n",
    "using either the Euclidean distance or the sum of the absolute values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start answer here\n",
    "\n",
    "# End Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Answer the following question:***\n",
    "\n",
    "Describe whether the result of the OpenCV based filter looks like the result you obtained earlier. If not, can you think of a reason why? (there may be some hints in the documentation above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write your answer here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Other OpenCV functions\n",
    "1. Displaying an image where all the colors are fully saturated, by using OpenCV's `cvtColor` function.\n",
    "2. Search for the `dilate` function in OpenCV and apply it to your image. Use a 5x5 kernel.\n",
    "\n",
    "Besides `dilate` OpenCV also provides functions to filter images such as `blur`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Color Histogram\n",
    "Next, we will explore the color histogram with `theDress.jpeg` which is included in\n",
    "the image folder on the VM. The color histogram is an example of a “global feature”, which means that each component of the vector represents the whole image (as opposed to representing a small region). In a color histogram, we simply count how many times each value of a color is present in a picture. A color histogram expresses the color information as three separate histograms.\n",
    "\n",
    "Implement your own color histogram algorithm using the following function body. Add your code to your google docs report. For our case, use num bins = `256` and\n",
    "num channels = `3`.\n",
    "\n",
    "```\n",
    "def my_colorHist(im, num_bins):\n",
    "    #Your code goes here\n",
    "    return histogram\n",
    "``` \n",
    "\n",
    "The function accepts an image, the number of histogram bins. It should return a\n",
    "histogram (Numpy array) for all color channels in the image, of size num bins x\n",
    "num channels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Answer the following question:***\n",
    "\n",
    "What do you expect that the histogram will look like. Relate your answer to the colors that you perceive the dress to be.\n",
    "\n",
    "#### Write your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_colorHist(im, num_bins):\n",
    "    # Start answer here\n",
    "    \n",
    "    # End answer here\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have experience with Matplotlib, there are excellent quick tutorials online to familiarize yourself with the basics\n",
    "\n",
    "(https://matplotlib.org/tutorials/introductory/pyplot.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Testing your algorithm\n",
    "An easy way to validate your algorithm is by comparing it to other implementations\n",
    "of a color histogram algorithm. Numpy, OpenCV and Matplotlib all have similar functions.\n",
    "\n",
    "#### ***Answer the following question:***\n",
    "Compare the results by creating a nice plot of both your result of my_colorHist() and one of the library color histogram functions. Is there a difference between the two plots? If so, why? Is this what you were expecting? Why or why not?\n",
    "\n",
    "#### Write your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
